{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbi44KtefDqB"
      },
      "source": [
        "**DEEP LEARNING**\n",
        "\n",
        "YOLOV3 - Object recognition\n",
        "\n",
        "GABRIEL JOSHUA . R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing the necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mount Google Drive to access the required files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the image from Google Drive and display it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "img = cv.imread('/gdrive/My Drive/DEEPLEARNING/dogs.jpg')\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess the image using YOLO's blobFromImage function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "blob = cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "r = blob[0, 0, :, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a copy of the original image for visualization purposes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "imgtemp = img.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the names of classes and assign random colors to each class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "classes = open('/gdrive/My Drive/DEEPLEARNING/coco.names').read().strip().split('\\n')\n",
        "np.random.seed(42)\n",
        "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype='uint8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the YOLO model using the configuration and weight files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "net = cv.dnn.readNetFromDarknet('/gdrive/My Drive/DEEPLEARNING/yolov3.cfg', '/gdrive/My Drive/DEEPLEARNING/yolov3.weights')\n",
        "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
        "CON = 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Determine the output layer names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "ln = net.getLayerNames()\n",
        "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set the blob as the input to the network and get the outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "net.setInput(blob)\n",
        "outputs = net.forward(ln)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to update the confidence threshold using a trackbar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def trackbar2(x):\n",
        "    confidence = x / 100\n",
        "    r = r0.copy()\n",
        "    for output in np.vstack(outputs):\n",
        "        if output[4] > confidence:\n",
        "            x, y, w, h = output[:4]\n",
        "            p0 = int((x - w/2) * 416), int((y - h/2) * 416)\n",
        "            p1 = int((x + w/2) * 416), int((y + h/2) * 416)\n",
        "            cv.rectangle(r, p0, p1, 1, 1)\n",
        "            cv.rectangle(imgtemp, p0, p1, 1, 1)\n",
        "    w1, h1 = imgtemp.shape[:2]\n",
        "    print(\"height:\", h1, \"width:\", w1)\n",
        "    cv2_imshow(imgtemp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the initial image for the trackbar function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "r0 = blob[0, 0, :, :]\n",
        "r = r0.copy()\n",
        "trackbar2(CON*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract bounding boxes, confidences, and class IDs from the outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "boxes = []\n",
        "confidences = []\n",
        "classIDs = []\n",
        "h, w = img.shape[:2]\n",
        "print(\"height:\", h, \"width:\", w)\n",
        "for output in outputs:\n",
        "    for detection in output:\n",
        "        scores = detection[5:]\n",
        "        classID = np.argmax(scores)\n",
        "        confidence = scores[classID]\n",
        "        if confidence > CON:\n",
        "            box = detection[:4] * np.array([w, h, w, h])\n",
        "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "            x = int(centerX - (width / 2))\n",
        "            y = int(centerY - (height / 2))\n",
        "            box = [x, y, int(width), int(height)]\n",
        "            boxes.append(box)\n",
        "            confidences.append(float(confidence))\n",
        "            classIDs.append(classID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Non-maximum suppression to eliminate redundant detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "score_threshold = 0.5\n",
        "nms_threshold = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "print(\"score threshold\", score_threshold, \"nms Threshold\", nms_threshold)\n",
        "\n",
        "indices = cv.dnn.NMSBoxes(boxes, confidences, score_threshold, nms_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Draw the final bounding boxes and labels on the image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "if len(indices) > 0:\n",
        "    for i in indices.flatten():\n",
        "        (x, y) = (boxes[i][0], boxes[i][1])\n",
        "        (w, h) = (boxes[i][2], boxes[i][3])\n",
        "        color = [int(c) for c in colors[classIDs[i]]]\n",
        "        cv.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "        text = \"{}: {:.4f}\".format(classes[classIDs[i]], confidences[i])\n",
        "        cv.putText(img, text, (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables and data you want to access outside the code block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "print(len(classes))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
